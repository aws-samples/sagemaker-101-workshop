{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker with XGBoost and Hyperparameter Tuning for Direct Marketing predictions \n",
    "_**Supervised Learning with Gradient Boosted Trees: A Binary Prediction Problem With Unbalanced Classes**_\n",
    "\n",
    "This notebook works well with the `Python 3 (Data Science)` kernel on SageMaker Studio, or `conda_python3` on classic SageMaker Notebook Instances\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Objective](#Objective)\n",
    "1. [Background](#Background-(Problem-Description-and-Approach))\n",
    "1. [Prepare our Environment](#Prepare-our-Environment)\n",
    "1. [Download and Explore the Data](#Download-and-Explore-the-Data)\n",
    "1. [Transform the Data](#Transform-the-Data)\n",
    "1. [Understand the Algorithm](#Understand-the-Algorithm)\n",
    "1. [Upload the Input Data to S3](#Upload-the-Input-Data-to-S3)\n",
    "1. [Train the Model](#Train-the-Model)\n",
    "1. [Deploy and Evaluate the Model](#Deploy-and-Evaluate-the-Model)\n",
    "1. [Hyperparameter Optimization (HPO)](#Hyperparameter-Optimization-(HPO))\n",
    "1. [Conclusions](#Conclusions)\n",
    "1. [Releasing Cloud Resources](#Releasing-Cloud-Resources)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "This workshop aims to give you an **example of using and tuning a SageMaker built-in algorithm**: Focussing on the **data interfaces** and SageMaker's automatic **Hyperparameter Optimization** (HPO) capabilities.\n",
    "\n",
    "Teaching in-depth data science approaches for tabular data is outside this scope, and we hope you can use this notebook as a starting point to modify for the needs of your future projects.\n",
    "\n",
    "---\n",
    "\n",
    "## Background (Problem Description and Approach)\n",
    "\n",
    "- **Direct marketing**: contacting potential new customers via mail, email, phone call etc. \n",
    "- **Challenge**: A) too many potential customers. B) limited resources of the approacher (time, money etc.).\n",
    "- **Problem: Which are the potential customers with the higher chance of becoming actual customers**? (so as to focus the effort only on them). \n",
    "- **Our setting**: A bank who wants to predict *whether a customer will enroll for a term deposit, after one or more phone calls*.\n",
    "- **Our approach**: Build a ML model to do this prediction, from readily available information e.g. demographics, past interactions etc. (features).\n",
    "- **Our tools**: We will be using the **XGBoost** algorithm implementation by **Amazon SageMaker**, and using SageMaker **Hyperparameter Optimization (HPO)** to improve our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prepare our Environment\n",
    "\n",
    "We'll need to:\n",
    "\n",
    "- **import** some useful libraries (as in any Python notebook)\n",
    "- **configure** the S3 bucket and folder where data should be stored (to keep our environment tidy)\n",
    "- **connect** to AWS in general (with [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)) and SageMaker in particular (with the [sagemaker SDK](https://sagemaker.readthedocs.io/en/stable/)), to use the cloud services\n",
    "\n",
    "While `boto3` is the general AWS SDK for Python, `sagemaker` provides some powerful, higher-level interfaces designed specifically for ML workflows.\n",
    "\n",
    "Note that you can safely ignore the WARNING about the pip version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # For matrix operations and numerical processing\n",
    "import pandas as pd  # For munging tabular data\n",
    "import time\n",
    "import os\n",
    "from util.classification_report import generate_classification_report  # helper function for classification reports\n",
    "\n",
    "# setting up SageMaker parameters\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "bucket_prefix = \"xgboost-example\"  # Location in the bucket to store our files\n",
    "sgmk_session = sagemaker.Session()\n",
    "sgmk_client = boto_session.client(\"sagemaker\")\n",
    "sgmk_role = sagemaker.get_execution_role()\n",
    "\n",
    "print(sgmk_role)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Download and Explore the Data\n",
    "\n",
    "Let's start by downloading the [direct marketing dataset](https://archive.ics.uci.edu/ml/datasets/bank+marketing) from UCI's ML Repository.\n",
    "\n",
    "We can run shell commands from inside Jupyter using the `!` prefix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget -P data/ -N https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"data/bank-additional.zip\", 'r') as zip_ref:\n",
    "    print(\"Unzipping...\")\n",
    "    zip_ref.extractall(\"data\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets read this into a Pandas data frame and take a look.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"./data/bank-additional/bank-additional-full.csv\", sep=\";\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)  # Make sure we can see all of the columns\n",
    "df_data.head()  # show part of the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Specifics on each of the features:**_\n",
    "\n",
    "*Demographics:*\n",
    "* `age`: Customer's age (numeric)\n",
    "* `job`: Type of job (categorical: 'admin.', 'services', ...)\n",
    "* `marital`: Marital status (categorical: 'married', 'single', ...)\n",
    "* `education`: Level of education (categorical: 'basic.4y', 'high.school', ...)\n",
    "\n",
    "*Past customer events:*\n",
    "* `default`: Has credit in default? (categorical: 'no', 'unknown', ...)\n",
    "* `housing`: Has housing loan? (categorical: 'no', 'yes', ...)\n",
    "* `loan`: Has personal loan? (categorical: 'no', 'yes', ...)\n",
    "\n",
    "*Past direct marketing contacts:*\n",
    "* `contact`: Contact communication type (categorical: 'cellular', 'telephone', ...)\n",
    "* `month`: Last contact month of year (categorical: 'may', 'nov', ...)\n",
    "* `day_of_week`: Last contact day of the week (categorical: 'mon', 'fri', ...)\n",
    "* `duration`: Last contact duration, in seconds (numeric). Important note: If duration = 0 then `y` = 'no'.\n",
    " \n",
    "*Campaign information:*\n",
    "* `campaign`: Number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "* `pdays`: Number of days that passed by after the client was last contacted from a previous campaign (numeric)\n",
    "* `previous`: Number of contacts performed before this campaign and for this client (numeric)\n",
    "* `poutcome`: Outcome of the previous marketing campaign (categorical: 'nonexistent','success', ...)\n",
    "\n",
    "*External environment factors:*\n",
    "* `emp.var.rate`: Employment variation rate - quarterly indicator (numeric)\n",
    "* `cons.price.idx`: Consumer price index - monthly indicator (numeric)\n",
    "* `cons.conf.idx`: Consumer confidence index - monthly indicator (numeric)\n",
    "* `euribor3m`: Euribor 3 month rate - daily indicator (numeric)\n",
    "* `nr.employed`: Number of employees - quarterly indicator (numeric)\n",
    "\n",
    "*Target variable* **(the one we want to eventually predict):**\n",
    "* `y`: Has the client subscribed to a term deposit? (binary: 'yes','no')\n",
    "\n",
    "---\n",
    "\n",
    "## A Brief Mention of SageMaker Autopilot\n",
    "\n",
    "While the SageMaker XGBoost algorithm needs particular data preparation as below, we could instead feed this raw data (translated from `;`-separated to `,`-separated) into [SageMaker Autopilot](https://aws.amazon.com/sagemaker/autopilot/) for a more end-to-end automated analysis.\n",
    "\n",
    "If you're running this exercise in SageMaker Studio and have some extra time, you can:\n",
    "\n",
    "- Run the cell below to upload the raw CSV to Amazon S3\n",
    "- Go to the *Components and Registries* tab (with the highlighted triangular logo) on the left hand side of the screen\n",
    "- Select *Experiments and trials* from the drop-down at the top of the tab\n",
    "- Click the *Create Experiment* button and set the URL below as the input data (you can leave most other settings as default)\n",
    "\n",
    "Note that running an Autopilot job will incur additional costs. You could consider selecting a smaller `Max Candidates` setting in the *Advanced Settings* section to speed up the job for this dataset: E.g. ~80 instead of the default 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.to_csv(\"./data/raw.csv\", index=False)\n",
    "raw_uri = sgmk_session.upload_data(\n",
    "    path=\"./data/raw.csv\",\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=bucket_prefix,\n",
    ")\n",
    "print(raw_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Transform the Data\n",
    "\n",
    "Cleaning up data is part of nearly every ML project. Several common steps include:\n",
    "\n",
    "* **Handling missing values**: In our case there are no missing values.\n",
    "* **Handling weird/outlier values**: There are some values in the dataset that may require manipulation.\n",
    "* **Converting categorical to numeric**: There are a lot of categorical variables in our dataset. We need to address this.\n",
    "* **Oddly distributed data**: We will be using XGBoost, which is a non-linear method, and is minimally affected by the data distribution.\n",
    "* **Remove unnecessary data**: There are lots of columns representing general economic features that may not be available during inference time.\n",
    "\n",
    "To summarise, we need to A) address some weird values, B) convert the categorical to numeric valriables and C) Remove unnecessary data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Many records have the value of \"999\" for `pdays`. It is very likely to be a 'magic' number to represent that *no contact was made before*. Considering that, we will create a new column called \"no_previous_contact\", then grant it value of \"1\" when pdays is 999 and \"0\" otherwise.\n",
    "\n",
    "2. In the `job` column, there are more than one categories for people who don't work e.g., \"student\", \"retired\", and \"unemployed\". It is very likely the decision to enroll or not to a term deposit depends a lot on whether the customer is working or not. A such, we generate a new column to show whether the customer is working based on `job` column.\n",
    "\n",
    "3. We will remove the economic features and `duration` from our data as they would need to be forecasted with high precision to be used as features during inference time.\n",
    "\n",
    "4. We convert categorical variables to numeric using *one hot encoding*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicator variable to capture when pdays takes a value of 999\n",
    "df_data[\"no_previous_contact\"] = np.where(df_data[\"pdays\"] == 999, 1, 0)\n",
    "\n",
    "# Indicator for individuals not actively employed\n",
    "df_data[\"not_working\"] = np.where(np.in1d(df_data[\"job\"], [\"student\", \"retired\", \"unemployed\"]), 1, 0)\n",
    "\n",
    "# remove unnecessary data\n",
    "df_model_data = df_data.drop(\n",
    "    [\"duration\", \n",
    "    \"emp.var.rate\", \n",
    "    \"cons.price.idx\", \n",
    "    \"cons.conf.idx\", \n",
    "    \"euribor3m\", \n",
    "    \"nr.employed\"], \n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df_model_data = pd.get_dummies(df_model_data)  # Convert categorical variables to sets of indicators\n",
    "\n",
    "# Replace \"y_no\" and \"y_yes\" with a single label column, and bring it to the front:\n",
    "df_model_data = pd.concat(\n",
    "    [\n",
    "        df_model_data[\"y_yes\"].rename(\"y\"),\n",
    "        df_model_data.drop([\"y_no\", \"y_yes\"], axis=1),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df_model_data.head()  # show part of the new transformed dataframe (which will be used for training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Understand the Algorithm\n",
    "\n",
    "We'll be using SageMaker's [built-in **XGBoost Algorithm**](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html): Benefiting from performance-optimized, pre-implemented functionality like multi-instance parallelization, and support for multiple input formats.\n",
    "\n",
    "In general to use the pre-built algorithms, we'll need to:\n",
    "\n",
    "- Refer to the [Common Parameters docs](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html) to see the **high-level configuration** and what features each algorithm has\n",
    "- Refer to the [algorithm docs](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) to understand the **detail** of the **data formats** and **(hyper)-parameters** it supports\n",
    "\n",
    "From these docs, we'll understand what data format we need to upload to S3 (next), and how to get the container image URI of the algorithm... which is listed on the Common Parameters page but can also be extracted through the SDK:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify container\n",
    "training_image = sagemaker.image_uris.retrieve(\"xgboost\", region=region, version=\"1.0-1\")\n",
    "\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Upload the Input Data to S3\n",
    "\n",
    "We know from [the algorithm docs](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html#InputOutput-XGBoost) that SageMaker XGBoost expects data in the **libSVM** or **CSV** formats, with:\n",
    "\n",
    "- The target variable in the first column, and\n",
    "- No header row\n",
    "\n",
    "...So before initializing training, we will:\n",
    "\n",
    "1. Suffle and split the data into **Training (70%)**, **Validation (20%)**, and **Test (10%)** sets\n",
    "2. Save the data in the format the algorithm expects (e.g. CSV)\n",
    "3. Upload the data to S3\n",
    "4. Define the training job input \"channels\" with explicit CSV content type tagging, via the SageMaker SDK [TrainingInput](https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html#sagemaker.inputs.TrainingInput) class\n",
    "\n",
    "The Training and Validation datasets will be used during the training (and tuning) phase, while the 'holdout' Test set will be used afterwards to evaluate the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and splitting dataset\n",
    "train_data, validation_data, test_data = np.split(\n",
    "    df_model_data.sample(frac=1, random_state=1729), \n",
    "    [int(0.7 * len(df_model_data)), int(0.9*len(df_model_data))],\n",
    ") \n",
    "\n",
    "# Create CSV files for Train / Validation / Test\n",
    "train_data.to_csv(\"data/train.csv\", index=False, header=False)\n",
    "validation_data.to_csv(\"data/validation.csv\", index=False, header=False)\n",
    "test_data.to_csv(\"data/test.csv\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload CSV files to S3 for SageMaker training\n",
    "train_uri = sgmk_session.upload_data(\n",
    "    path=\"data/train.csv\",\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=bucket_prefix,\n",
    ")\n",
    "val_uri = sgmk_session.upload_data(\n",
    "    path=\"data/validation.csv\",\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=bucket_prefix,\n",
    ")\n",
    "\n",
    "\n",
    "# Define the data input channels for the training job:\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(train_uri, content_type=\"csv\")\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(val_uri, content_type=\"csv\")\n",
    "\n",
    "print(f\"{s3_input_train.config}\\n\\n{s3_input_validation.config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Train the Model\n",
    "\n",
    "Training a model on SageMaker follows the usual steps with other ML libraries (e.g. SciKit-Learn):\n",
    "1. Initiate a session (we did this up top).\n",
    "2. Instantiate an estimator object for our algorithm (XGBoost).\n",
    "3. Define its hyperparameters.\n",
    "4. Start the training job.\n",
    "\n",
    "#### A small competition!\n",
    "SageMaker's XGBoost includes 38 parameters. You can find more information about them [here](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html).\n",
    "For simplicity, we choose to experiment only with a few of them.\n",
    "\n",
    "**Please select values for the 4 hyperparameters (by replacing the ?) based on the provided ranges.** Later we will see which model performed best and compare it with the one from the Hyperparameter Optimization step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate an XGBoost estimator object\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=training_image,  # XGBoost algorithm container\n",
    "    instance_type=\"ml.m5.xlarge\",  # type of training instance\n",
    "    instance_count=1,  # number of instances to be used\n",
    "    role=sgmk_role,  # IAM role to be used\n",
    "    max_run=20*60,  # Maximum allowed active runtime\n",
    "    use_spot_instances=True,  # Use spot instances to reduce cost\n",
    "    max_wait=30*60,  # Maximum clock time (including spot delays)\n",
    ")\n",
    "\n",
    "# define its hyperparameters\n",
    "estimator.set_hyperparameters(\n",
    "    num_round=150,     # int: [1,300]\n",
    "    max_depth=5,     # int: [1,10]\n",
    "    alpha=2.5,         # float: [0,5]\n",
    "    eta=0.5,           # float: [0,1]\n",
    "    objective=\"binary:logistic\",\n",
    ")\n",
    "\n",
    "# start a training (fitting) job\n",
    "estimator.fit({ \"train\": s3_input_train, \"validation\": s3_input_validation })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Deploy and Evaluate the Model\n",
    "\n",
    "### Deployment\n",
    "\n",
    "Now that we've trained the xgboost algorithm on our data, deploying the model (hosting it behind a real-time endpoint) is just one function call!\n",
    "\n",
    "This deployment might take **up to 10 minutes**, and by default the code will wait for the deployment to complete.\n",
    "\n",
    "If you like, you can instead:\n",
    "\n",
    "- Un-comment the `wait=False` parameter\n",
    "- Use the [Endpoints page of the SageMaker Console](https://console.aws.amazon.com/sagemaker/home?#/endpoints) to check the status of the deployment\n",
    "- Skip over the *Evaluation* section below (which won't run until the deployment is complete), and start the Hyperparameter Optimization job - which will take a while to run too, so can be started in parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time endpoint:\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    # wait=False,  # Remember, predictor.predict() won't work until deployment finishes!\n",
    "\n",
    "    # We will also turn on data capture here, in case you want to experiment with monitoring later:\n",
    "    data_capture_config=sagemaker.model_monitor.DataCaptureConfig(\n",
    "        enable_capture=True,\n",
    "        sampling_percentage=100,\n",
    "        destination_s3_uri=f\"s3://{bucket_name}/{bucket_prefix}/data-capture\",\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Since SageMaker is a general purpose ML platform and our endpoint is a web service, we'll need to be explicit that we're sending in tabular data (_serialized_ in CSV string format for the HTTPS request) and expect a tabular response (to be _deserialized_ from CSV to numpy).\n",
    "\n",
    "In the SageMaker SDK (from v2), this packing and unpacking of the payload for the web endpoint is handled by [serializer classes](https://sagemaker.readthedocs.io/en/stable/api/inference/serializers.html) and [deserializer classes](https://sagemaker.readthedocs.io/en/stable/api/inference/deserializers.html).\n",
    "\n",
    "Unfortunately the pre-built `CSVDeserializer` produces nested Python lists of strings, rather than a numpy array of numbers - so rather than bothering to implement a custom class (like the examples [here](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/deserializers.py)) we'll be lazy and take this as a post-processing step.\n",
    "\n",
    "With this setup ready, requesting inferences is as easy as calling `predictor.predict()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.serializer = sagemaker.serializers.CSVSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.CSVDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_numpy = test_data.drop([\"y\"], axis=1).values\n",
    "\n",
    "predictions = np.array(predictor.predict(X_test_numpy), dtype=float).squeeze()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each number in this vector is the **predicted probability** (in the interval [0,1]) of a potential customer enrolling for a term deposit.\n",
    "\n",
    "- 0: The person **will not** enroll\n",
    "- 1: The person **will** enroll (making them a good candidate for direct marketing)\n",
    "\n",
    "If we like, we could stitch these predictions back on to the original dataframe to explore performance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.concat(\n",
    "    [\n",
    "        pd.Series(predictions, name=\"y_pred\", index=test_data.index),\n",
    "        test_data,\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "test_results.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...Or use this function we provided to generate a more **comprehensive model report**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_classification_report(\n",
    "    y_real=test_data[\"y\"].values, \n",
    "    y_predict_proba=predictions, \n",
    "    decision_threshold=0.5,\n",
    "    class_names_list=[\"Did not enroll\", \"Enrolled\"],\n",
    "    title=\"Initial model\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hyperparameter Optimization (HPO)\n",
    "*Note, with the default settings below, the hyperparameter tuning job can take up to ~20 minutes to complete.*\n",
    "\n",
    "We will use SageMaker HyperParameter Optimization (HPO) to automate the searching process effectively. Specifically, we **specify a range**, or a list of possible values in the case of categorical hyperparameters, for each of the hyperparameter that we plan to tune.\n",
    "\n",
    "SageMaker hyperparameter tuning will automatically launch **multiple training jobs** with different hyperparameter settings, evaluate results of those training jobs based on a predefined \"objective metric\", and select the hyperparameter settings for future attempts based on previous results. For each hyperparameter tuning job, we will specify the maximum number of HPO tries (`max_jobs`) and how many of these can happen in parallel (`max_parallel_jobs`).\n",
    "\n",
    "Tip: `max_parallel_jobs` creates a **trade-off between performance and speed** (better hyperparameter values vs how long it takes to find these values). If `max_parallel_jobs` is large, then HPO is faster, but the discovered values may not be optimal. Smaller `max_parallel_jobs` will increase the chance of finding optimal values, but HPO will take more time to finish.\n",
    "\n",
    "Next we'll specify the objective metric that we'd like to tune and its definition, which includes the regular expression (Regex) needed to extract that metric from the CloudWatch logs of the training job. Since we are using built-in XGBoost algorithm here, it emits two predefined metrics: **validation:auc** and **train:auc**.\n",
    "\n",
    "Area Under the ROC Curve (AUC) measures the ability of a binary ML model to predict a higher score for positive examples as compared to negative examples. [See Machine Learning Key Concepts](https://docs.aws.amazon.com/machine-learning/latest/dg/amazon-machine-learning-key-concepts.html)\n",
    "\n",
    "We elected to monitor *validation:auc* as you can see below. In this case (because it's pre-built for us), we only need to specify the metric name.\n",
    "\n",
    "For more information on the documentation of the Sagemaker HPO please refer [here](https://sagemaker.readthedocs.io/en/stable/tuner.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required HPO objects\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "# set up hyperparameter ranges\n",
    "ranges = {\n",
    "    \"num_round\": IntegerParameter(1, 300),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 5),\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "}\n",
    "\n",
    "# set up the objective metric\n",
    "objective = \"validation:auc\"\n",
    "\n",
    "# instantiate a HPO object\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=estimator,              # the SageMaker estimator object\n",
    "    hyperparameter_ranges=ranges,     # the range of hyperparameters\n",
    "    max_jobs=10,                      # total number of HPO jobs\n",
    "    max_parallel_jobs=2,              # how many HPO jobs can run in parallel\n",
    "    strategy=\"Bayesian\",              # the internal optimization strategy of HPO\n",
    "    objective_metric_name=objective,  # the objective metric to be used for HPO\n",
    "    objective_type=\"Maximize\",        # maximize or minimize the objective metric\n",
    ")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch HPO\n",
    "Now we can launch a hyperparameter tuning job by calling *fit()* function. After the hyperparameter tuning job is created, we can go to SageMaker console to track the progress of the hyperparameter tuning job until it is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start HPO\n",
    "tuner.fit({ \"train\": s3_input_train, \"validation\": s3_input_validation })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HPO jobs often take quite a long time to finish and as such, sometimes you may want to free up the notebook and then resume the wait later.\n",
    "\n",
    "Just like the Estimator, we won't be able to `deploy()` the model until the HPO tuning job is complete; and the status is visible through both the [AWS Console](https://console.aws.amazon.com/sagemaker/home?#/hyper-tuning-jobs) and the [SageMaker API](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeHyperParameterTuningJob.html). We could for example write a polling script like the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait, until HPO is finished\n",
    "hpo_state = None\n",
    "\n",
    "while hpo_state is None or hpo_state == \"InProgress\":\n",
    "    if hpo_state is not None:\n",
    "        print(\"-\", end=\"\")\n",
    "        time.sleep(60)  # Poll once every 1 min\n",
    "    hpo_state = sgmk_client.describe_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName=tuner.latest_tuning_job.job_name,\n",
    "    )[\"HyperParameterTuningJobStatus\"]\n",
    "\n",
    "print(\"\\nHPO state:\", hpo_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy and test optimized model\n",
    "Deploying the best model is another simple `.deploy()` call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# deploy the best model from HPO\n",
    "hpo_predictor = tuner.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),\n",
    "    deserializer=sagemaker.deserializers.CSVDeserializer(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once deployed, we can now evaluate the performance of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the predicted probabilities of the best model\n",
    "hpo_predictions = np.array(hpo_predictor.predict(X_test_numpy), dtype=float).squeeze()\n",
    "print(hpo_predictions)\n",
    "\n",
    "# generate report for the best model\n",
    "generate_classification_report(\n",
    "    y_real=test_data[\"y\"].values, \n",
    "    y_predict_proba=hpo_predictions, \n",
    "    decision_threshold=0.5,\n",
    "    class_names_list=[\"Did not enroll\",\"Enrolled\"],\n",
    "    title=\"Best model (with HPO)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "In our run, the optimized HPO model exhibited an AUC of ~0.774: fairly higher than our first-guess parameter combination!\n",
    "\n",
    "Depending on the number of tries, HPO can find a better performing model faster, compared to simply trying different hyperparameters by trial and error or grid search. You can learn more in-depth details about SageMaker HPO [here](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html).\n",
    "\n",
    "SageMaker built-in algorithms are great for getting a first model fast, and combining them with SageMaker HPO can really boost their accuracy.\n",
    "\n",
    "As we mentioned here, the best way to success with a built-in algorithm is to **read the [algorithm's doc pages](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html) carefully** - to understand what data format and parameters it needs!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Releasing Cloud Resources\n",
    "\n",
    "It's generally a good practice to deactivate all endpoints which are not in use.  \n",
    "\n",
    "Please uncomment the following lines and run the cell in order to deactivate the 2 endpoints that were created before. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "# hpo_predictor.delete_endpoint(delete_endpoint_config=True)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
