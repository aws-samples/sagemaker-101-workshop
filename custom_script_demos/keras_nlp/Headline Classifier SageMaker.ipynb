{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 엔드투엔드 NLP: 뉴스 헤드라인 분류기(SageMaker 버전)\n",
    "\n",
    "_**네 가지 도메인 간 뉴스 헤드라인을 분류하기 위해 Keras 기반 모델 학습**_\n",
    "\n",
    "이 노트북은 SageMaker 스튜디오의 `Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)`  커널 또는 클래식 세이지메이커 노트북 인스턴스의 `conda_tensorflow2_p37`에서 잘 작동합니다.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "이전 '로컬 버전' 노트북에 이어, 여기서는 리소스를 더 잘 활용하기 위해 별도의 인프라에서 모델 훈련 및 배포를 트리거하는 방법을 보여줍니다.\n",
    "\n",
    "pip 버전에 대한 경고는 무시해도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First install some libraries which might not be available across all kernels (e.g. in Studio):\n",
    "!pip install \"ipywidgets<8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News Aggregator 데이터셋 다운로드\n",
    "\n",
    "[AWS의 오픈 데이터 레지스트리](https://registry.opendata.aws/fast-ai-nlp/) 퍼블릭 리포지토리에서 **FastAI AG 뉴스** 데이터 세트를 다운로드합니다. 이 데이터 세트에는 뉴스 헤드라인과 그에 해당하는 클래스의 표가 포함되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "local_dir = \"data\"\n",
    "# Download the AG News data from the Registry of Open Data on AWS.\n",
    "!mkdir -p {local_dir}\n",
    "!aws s3 cp s3://fast-ai-nlp/ag_news_csv.tgz {local_dir} --no-sign-request\n",
    "\n",
    "# Un-tar the AG News data.\n",
    "!tar zxf {local_dir}/ag_news_csv.tgz -C {local_dir}/ --strip-components=1 --no-same-owner\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 세트를 시각화해 봅시다.\n",
    "\n",
    "데이터 처리 작업을 위해 ag_news_csv/train.csv 파일을 Pandas 데이터 프레임에 로드하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import util.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_names = [\"CATEGORY\", \"TITLE\", \"CONTENT\"]\n",
    "# we use the train.csv only\n",
    "df = pd.read_csv(f\"{local_dir}/train.csv\", names=column_names, header=None, delimiter=\",\")\n",
    "# shuffle the DataFrame rows\n",
    "df = df.sample(frac=1, random_state=1337)\n",
    "# make the category classes more readable\n",
    "mapping = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tech\"}\n",
    "df = df.replace({\"CATEGORY\": mapping})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 연습에서는 **아래 내용만 사용하겠습니다**:\n",
    "\n",
    "- 뉴스 기사의 **제목**(헤드라인)을 입력으로 사용합니다.\n",
    "- 대상 변수로 **카테고리**를 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"CATEGORY\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has **four article categories** with equal weighting:\n",
    "\n",
    "- Business\n",
    "- Sci/Tech\n",
    "- Sports\n",
    "- World\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자연어 전처리\n",
    "\n",
    "텍스트 데이터를 알고리즘이 모델을 생성하는 데 사용할 수 있는 숫자 형식으로 변환하기 위해 몇 가지 기본 처리를 수행합니다.\n",
    "\n",
    "라벨 더미 인코딩, 문서 토큰화, 입력 특징 차원에 대한 고정 시퀀스 길이 설정, 고정 길이 입력 벡터를 갖도록 문서 패딩과 같은 NLP 워크로드에 대한 일반적인 사전 처리를 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Encode the Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_y, labels = util.preprocessing.dummy_encode_labels(df, \"CATEGORY\")\n",
    "print(labels)\n",
    "print(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"CATEGORY\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  토큰화 및 고정 시퀀스 길이 설정하기\n",
    "\n",
    "개별 문자가 아닌 보다 의미 있는 단어 수준에서 입력을 설명하고, 입력 특징 차원의 고정된 길이를 보장하고자 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7bcf422f-0e75-4d49-b3b1-12553fcaf4ff",
    "_uuid": "46b7fc9aef5a519f96a295e980ba15deee781e97",
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_docs, tokenizer = util.preprocessing.tokenize_and_pad_docs(df, \"TITLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"TITLE\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 임베딩 가져오기\n",
    "\n",
    "단어를 숫자 형태로 표현하기 위해 어휘의 각 단어에 대해 미리 학습된 벡터 표현을 사용합니다: 이 경우 영어 이외의 다양한 언어에도 사용할 수 있는 [pre-trained word embeddings from FastText](https://fasttext.cc/docs/en/crawl-vectors.html)을 사용할 것입니다.\n",
    "\n",
    "SageMaker에 내장된 [BlazingText algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext.html)을 사용하여 도메인별 맞춤 단어 임베딩을 학습할 수도 있습니다. 방법을 보여주는 예제 노트북은 공식 [blazingtext_word2vec_text8 sample](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/introduction_to_amazon_algorithms/blazingtext_word2vec_text8)을 참조하세요.\n",
    "\n",
    "> ⚠️ 이 셀을 로컬 노트북의 `get_word_embeddings()` 셀과 동시에 실행하면 간혹 파일 형식 오류가 발생할 수 있습니다. 이 경우, 이 셀을 다시 실행하기 전에 `data/embeddings` 폴더를 삭제해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "embedding_matrix = util.preprocessing.get_word_embeddings(tokenizer, f\"{local_dir}/embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "593bfd0a-b703-4e87-96dd-a7eb98e6940e",
    "_uuid": "f71c5f0b731d3418d3cb83be758233b5030da29d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(\n",
    "    file=f\"{local_dir}/embeddings/docs-embedding-matrix\",\n",
    "    arr=embedding_matrix,\n",
    "    allow_pickle=False,\n",
    ")\n",
    "vocab_size = embedding_matrix.shape[0]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 및 테스트 세트 분할\n",
    "\n",
    "마지막으로 데이터를 모델 훈련 세트와 평가 세트로 나눠야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    processed_docs,\n",
    "    encoded_y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(f\"{local_dir}/train\", exist_ok=True)\n",
    "np.save(f\"{local_dir}/train/train_X.npy\", X_train)\n",
    "np.save(f\"{local_dir}/train/train_Y.npy\", y_train)\n",
    "os.makedirs(f\"{local_dir}/test\", exist_ok=True)\n",
    "np.save(f\"{local_dir}/test/test_X.npy\", X_test)\n",
    "np.save(f\"{local_dir}/test/test_Y.npy\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실행 역할, 세션 및 S3 버킷 설정 ###\n",
    "\n",
    "SageMaker 학습 작업의 기본 데이터 소스는 (거의) 항상 Amazon S3입니다. SageMaker 학습 작업에 사용할 수 있도록 사전 처리된 데이터를 여기에 업로드해야 합니다. \n",
    "\n",
    "지정하는 것부터 시작하겠습니다:\n",
    "- 학습 및 모델 데이터에 사용할 S3 버킷과 접두사를 지정합니다. 이 버킷은 노트북 인스턴스, 학습 및 호스팅과 동일한 리전 내에 있어야 합니다. 버킷을 지정하지 않으면 SageMaker SDK는 동일한 리전에서 미리 정의된 명명 규칙에 따라 기본 버킷을 생성합니다. \n",
    "- SageMaker에 데이터 액세스 권한을 부여하는 데 사용되는 IAM 역할 ARN입니다. SageMaker 파이썬 SDK에서 **get_execution_role** 메서드를 사용하여 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "bucket_name = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon S3에 데이터 업로드\n",
    "S3에 데이터를 업로드하는 한 가지 방법은 대상 버킷과 소스 디렉터리의 콘텐츠를 동기화하는 상위 수준 [aws s3 sync](https://docs.aws.amazon.com/cli/latest/userguide/cli-services-s3-commands.html#using-s3-commands-managing-objects-sync) 명령을 사용하는 것입니다. 이 명령은 다음과 같은 옵션도 지원합니다:\n",
    "\n",
    "- ```--delete```, 대상에서 소스에 없는 모든 오브젝트를 제거합니다.\n",
    "- 소스 폴더에서 모든 것을 복사하는 대신 파일/개체를 필터링하려면 ```--exclude``` 및 ```--include```를 사용합니다.\n",
    "\n",
    "Python을 통해서도 S3로 작업할 수 있지만(예: [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html) 또는 [SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/api/utility/s3.html)), S3 동기화 CLI는 기본적으로 *멀티 스레드*를 지원합니다: 따라서 더 복잡한 코드를 도입하지 않고도 노트북에서 빠르게 전송할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 sync --quiet --delete {local_dir} s3://{bucket_name}/news --exclude \"*\" --include \"*.npy\"\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 입력(\"채널\") 구성\n",
    "로컬 버전의 노트북([Headline Classifier Local.ipynb](Headline%20Classifier%20Local.ipynb))에는 학습, 테스트, 임베딩의 세 가지 데이터 입력이 있습니다. SageMaker 용어로 각 입력 데이터는 \"채널\"입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_channel = f\"s3://{bucket_name}/news/train\"\n",
    "test_channel = f\"s3://{bucket_name}/news/test\"\n",
    "embeddings_channel = f\"s3://{bucket_name}/news/embeddings\"\n",
    "\n",
    "inputs = {\"train\": train_channel, \"test\": test_channel, \"embeddings\": embeddings_channel}\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker에서 차별화된 인프라로 학습하기\n",
    "\n",
    "이번에는 이전 노트북의 모델 빌드 및 학습 코드([Headline Classifier Local.ipynb](Headline%20Classifier%20Local.ipynb))를 **src** 디렉터리의 [**main.py**](src/main.py) 스크립트에 패키징했습니다.\n",
    "\n",
    "이 스크립트 파일에서 모델을 학습하고 배포하기 위해 상위 레벨의 [SageMaker Python SDK를 통한 텐서플로우 프레임워크 컨테이너](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html)를 사용할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 빌드된 컨테이너로 Amazon SageMaker에서 Tensorflow 스크립트를 실행하는 방법 ###\n",
    "\n",
    "AWS는 주요 머신러닝 프레임워크에서 프로젝트를 빠르게 구축할 수 있도록 사전 패키지된 Docker 이미지 세트를 제공합니다: [SageMaker 프레임워크 컨테이너](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers-prebuilt.html).\n",
    "\n",
    "이 컨테이너는 GPU 드라이버, 서빙 스택 구현, 핵심 라이브러리 등과 같은 기본 설정을 처리하므로 트레이닝 프로세스 및 추론 동작 오버라이드를 위한 Python 스크립트만 간단히 삽입하면 됩니다. 심지어 컨테이너 이미지에 빌드할 필요 없이 시작 시 동적으로 설치할 추가 종속성을 지정하는 *requirements.txt* 파일을 제공할 수도 있습니다.\n",
    "\n",
    "**따라서 첫 번째 작업은 스크립트와 런타임 간의 인터페이스**를 이해하는 것입니다: 스크립트가 입력 데이터를 어떻게 읽을 것인가? 매개변수는? 결과를 어디에 저장해야 할까요?\n",
    "\n",
    "#### 학습 중 컨테이너 실행\n",
    "\n",
    "Amazon SageMaker가 트레이닝을 실행할 때, 트레이닝 스크립트(entry_point 입력)는 일반 Python 프로그램과 마찬가지로 실행됩니다. 여러 파일이 `/opt/ml` 디렉토리에 배치되어 있습니다. 이 파일들은 스크립트 내에서 액세스할 수 있는 위치입니다. 이 파일의 사용 예는 [**main.py**](src/main.py)에서 확인할 수 있습니다:\n",
    "\n",
    "\n",
    "    /opt/ml\n",
    "    |-- code\n",
    "    |   `-- <our script(s)>\n",
    "    |-- input\n",
    "    |   |-- config\n",
    "    |   |   |-- hyperparameters.json\n",
    "    |   |   `-- resourceConfig.json\n",
    "    |   `-- data\n",
    "    |       `-- <channel_name>\n",
    "    |           `-- <input data>\n",
    "    |-- model\n",
    "    |   `-- <model files>\n",
    "    `-- output\n",
    "        `-- failure\n",
    " \n",
    "##### 입력\n",
    "\n",
    "* `/opt/ml/input/config`에는 프로그램 실행 방식을 제어하는 정보가 들어 있습니다. `hyperparameters.json`은 하이퍼파라미터 이름을 값으로 변환한 JSON 형식의 딕셔너리입니다. 이 값은 항상 문자열이므로 변환해야 할 수도 있습니다. `resourceConfig.json` 은 분산 학습에 사용되는 네트워크 레이아웃을 설명하는 JSON 형식의 파일입니다. scikit-learn은 분산 학습을 지원하지 않으므로 여기서는 무시하겠습니다.\n",
    "* (파일 모드의 경우) `/opt/ml/input/data/<channel_name>/`에는 해당 채널의 입력 데이터가 포함됩니다. 채널은 CreateTrainingJob 호출에 따라 생성되지만 일반적으로 채널이 알고리즘이 예상하는 것과 일치하는 것이 중요합니다. 각 채널의 파일은 S3 키 구조로 표시된 트리 구조를 유지하면서 S3에서 이 디렉토리로 복사됩니다. \n",
    "* (파이프 모드의 경우) `/opt/ml/input/data/<channel_name>_<epoch_number>`는 주어진 에포크에 대한 파이프입니다. 에포크는 0에서 시작하여 읽을 때마다 하나씩 올라갑니다. 실행할 수 있는 에포크 수에는 제한이 없지만 다음 에포크를 읽기 전에 각 파이프를 닫아야 합니다.\n",
    "\n",
    "##### 출력\n",
    "    \n",
    "* `/opt/ml/model/`은 알고리즘이 생성하는 모델을 작성하는 디렉토리입니다. 모델은 원하는 모든 형식이 가능합니다. 단일 파일 또는 전체 디렉토리 트리가 될 수 있습니다. 세이지메이커는 이 디렉토리에 있는 모든 파일을 압축된 타르 아카이브 파일로 패키징합니다. 이 파일은 `DescribeTrainingJob` 결과에서 반환된 S3 위치에서 사용할 수 있습니다.\n",
    "* `/opt/ml/output`은 알고리즘이 작업이 실패한 이유를 설명하는 `실패` 파일을 작성할 수 있는 디렉터리입니다. 이 파일의 내용은 `DescribeTrainingJob` 결과의 `FailureReason` 필드에 반환됩니다. 성공한 작업의 경우 이 파일은 무시되므로 이 파일을 작성할 이유가 없습니다.\n",
    "\n",
    "#### 추가 정보\n",
    "\n",
    "자세한 내용은 다음을 참조하세요:\n",
    "\n",
    "- [SageMaker Python SDK guide for TensorFlow](https://sagemaker.readthedocs.io/en/stable/using_tf.html), 텐서플로우 프레임워크 클래스에 대한 [API 문서](https://sagemaker.readthedocs.io/en/stable/sagemaker.tensorflow.html)를 참고하세요.\n",
    "- 기본 컨테이너 이미지를 정의하는 GitHub의 [AWS Deep Learning Containers repository](https://github.com/aws/deep-learning-containers).\n",
    "- 학습 및 서비스를 위한 프레임워크 코드에 대한 자세한 내용은 오픈 소스 SageMaker [TensorFlow Training Toolkit](https://github.com/aws/sagemaker-tensorflow-training-toolkit) 및 [TensorFlow Serving Container](https://github.com/aws/sagemaker-tensorflow-serving-container)를 참조하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow as TensorFlowEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스크립트는 별도의 컨테이너에서 실행되지만, 필요한 매개변수는 SageMaker를 통해 전달할 수 있습니다:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\"epochs\": 5, \"max_seq_len\": 40, \"num_classes\": 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 `TensorFlow` 추정기(estimator) 객체가 있고, 이 객체에 대한 하이퍼 파라미터를 설정했으며, 알고리즘과 연결된 데이터 채널이 있습니다. 이제 남은 일은 알고리즘을 학습하는 것입니다. 다음 명령은 몇 가지 단계로 구성된 이 학습을 실행합니다:\n",
    "\n",
    "- 먼저, `TensorFlow` 추정기(estimator) 클래스를 생성할 때 요청했던 인스턴스를 프로비저닝하고 적절한 라이브러리를 사용하여 설정합니다.\n",
    "- 그런 다음 채널의 데이터를 인스턴스로 다운로드합니다.\n",
    "- 이 작업이 완료되면 학습 작업이 코드 실행을 시작합니다.\n",
    "\n",
    "프로비저닝과 데이터 다운로드는 데이터의 크기와 컨테이너 이미지에 따라 다소 시간이 걸립니다. \n",
    "\n",
    "작업이 완료되면 \"작업 완료\" 메시지가 나타납니다. 학습된 모델은 추정기(estimator)에서 'output_path'로 설정된 S3 버킷에서 찾을 수 있습니다.\n",
    "\n",
    "여기서는 컴퓨팅 최적화(CPU) `ml.c5.xlarge` 인스턴스 유형을 사용하여 학습 작업을 실행합니다. 더 큰 딥 러닝 모델이나 데이터 세트의 경우, `ml.p*` 또는 `ml.g*`와 같은 GPU 가속 유형을 사용하여 학습 속도를 더욱 높일 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"loss\", \"Regex\": \"loss: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"accuracy\", \"Regex\": \"acc: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"validation:loss\", \"Regex\": \"Validation.*loss=([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"validation:accuracy\", \"Regex\": \"Validation.*acc=([0-9\\\\.]+)\"},\n",
    "]\n",
    "\n",
    "estimator = TensorFlowEstimator(\n",
    "    framework_version=\"2.4\",\n",
    "    py_version=\"py37\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    role=role,\n",
    "    entry_point=\"main.py\",\n",
    "    source_dir=\"./src\",\n",
    "    distribution={\"parameter_server\": {\"enabled\": True}},\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    base_job_name=\"news-keras\",\n",
    "    max_run=20 * 60,  # Maximum allowed active runtime\n",
    "    ## Here Spot is left OFF by default to avoid delays, but easy to turn on by un-commenting:\n",
    "    # use_spot_instances=True,  # Use spot instances to reduce cost\n",
    "    # max_wait=30*60,  # Maximum clock time (including spot wait time)\n",
    ")\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the training job is running take a minute to look at the `main.py` script. You can see how we have adapted the our original local code from [Headline Classifier Local.ipynb](Headline%20Classifier%20Local.ipynb) to run on Sagemaker.\n",
    "\n",
    "학습 작업이 실행되는 동안 잠시 시간을 내어 `main.py` 스크립트를 살펴보세요. [Headline Classifier Local.ipynb](Headline%20Classifier%20Local.ipynb)의 원래 로컬 코드를 Sagemaker에서 실행하도록 어떻게 조정했는지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 사용: 호스팅 / 추론\n",
    "학습이 완료되면 학습된 모델을 Amazon SageMaker에서 호스팅하는 [real-time inference endpoint](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)로 배포할 수 있습니다. 이렇게 하면 필요에 따라 모델에서 예측(또는 추론)을 쿼리할 수 있습니다.\n",
    "\n",
    "참고하세요:\n",
    "\n",
    "- 배치 추론 상황(예: 테스트 데이터 세트에서 메트릭 계산)의 경우, 대신 [SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)을 사용하는 것이 좋습니다. 자세한 내용은 SageMaker 파이썬 SDK 문서에서 [세이지메이커 배치 변환 사용하기](https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-batch-transform)를 참고하세요.\n",
    "- 학습한 것과 동일한 **유형**의 인스턴스를 사용할 필요는 없습니다. 이 테스트 엔드포인트는 매우 적은 트래픽을 처리할 것이므로 더 저렴한 유형을 사용할 수 있습니다:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.medium\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이제 모델이 프로덕션 환경에서 RESTful API로 작동합니다!\n",
    "\n",
    "몇 가지 예제 헤드라인으로 모델을 평가해 봅시다...\n",
    "\n",
    "위젯을 사용하는 데 어려움이 있다면 파이썬에서 `classify()` 함수를 호출하면 됩니다.\n",
    "\n",
    "헤드라인을 창의적으로 만들 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython import display\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def classify(text):\n",
    "    \"\"\"Classify a headline and print the results\"\"\"\n",
    "    encoded_example = tokenizer.texts_to_sequences([text])\n",
    "    # Pad documents to a max length of 40 words\n",
    "    max_length = 40\n",
    "    padded_example = pad_sequences(encoded_example, maxlen=max_length, padding=\"post\")\n",
    "    result = predictor.predict(padded_example.tolist())\n",
    "    print(result)\n",
    "    ix = np.argmax(result[\"predictions\"])\n",
    "    print(f\"Predicted class: '{labels[ix]}' with confidence {result['predictions'][0][ix]:.2%}\")\n",
    "\n",
    "\n",
    "# Either try out the interactive widget:\n",
    "interaction = widgets.interact_manual(\n",
    "    classify,\n",
    "    text=widgets.Text(\n",
    "        value=\"The markets were bullish after news of the merger\",\n",
    "        placeholder=\"Type a news headline...\",\n",
    "        description=\"Headline:\",\n",
    "        layout=widgets.Layout(width=\"99%\"),\n",
    "    ),\n",
    ")\n",
    "interaction.widget.children[1].description = \"Classify!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Or just use the function to classify your own headline:\n",
    "classify(\"Retailers are expanding after the recent economic growth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "학습이 완료되는 즉시 리소스를 삭제하는 학습 작업과 달리, 실시간 엔드포인트 배포는 엔드포인트를 종료할 때까지 인스턴스를 프로비저닝합니다....\n",
    "\n",
    "따라서 리소스를 아껴서 사용하고 더 이상 필요하지 않으면 리소스를 삭제해야 합니다. 아래 셀의 댓글을 취소하고 실행하여 엔드포인트를 삭제할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (옵션) 자동 하이퍼파라미터 최적화 - HPO\n",
    "\n",
    "모델 성능을 조정하기 위해 매개변수를 수동으로 조정하는 대신 SageMaker의 도움을 받을 수 있습니다.\n",
    "\n",
    "SageMaker에 아래 정보를 간단히 알려주면 됩니다:\n",
    "\n",
    "- 각 매개변수의 유형과 허용 범위,\n",
    "- 최적화하고자 하는 메트릭, 그리고\n",
    "- 전략 및 리소스 제약 조건\n",
    "\n",
    "...그러면 서비스가 최적의 조합을 찾을 수 있도록 작업을 설정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (하이퍼-)파라미터 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    "    IntegerParameter,\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"epochs\": IntegerParameter(2, 7),\n",
    "    \"learning_rate\": ContinuousParameter(0.01, 0.2),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 목표 메트릭\n",
    "\n",
    "SageMaker의 '메트릭'은 정규 표현식을 통해 작업의 콘솔 출력에서 스크랩됩니다.\n",
    "\n",
    "모니터링할 메트릭을 여러 개 정의할 수 있지만, HPO에서는 그 중 정확히 한 개를 최적화할 **목표** 메트릭으로 지정해야 합니다:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (See metric_definitions above)\n",
    "objective_metric_name = \"validation:accuracy\"\n",
    "objective_type = \"Maximize\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 튜닝 작업 시작\n",
    "\n",
    "위에서 이미 Estimator를 정의했으므로 약간의 조정을 통해 구성된 것을 재사용하겠습니다.\n",
    "\n",
    "추정기(Estimator)의 '하이퍼파라미터'가 기본값으로 사용되며, 적절한 경우 하이퍼파라미터튜너로 재정의된다는 점에 유의하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Keep per-job resources modest, so that parallel jobs don't hit any limits:\n",
    "estimator.instance_type = \"ml.c5.xlarge\"\n",
    "estimator.instance_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    base_tuning_job_name=\"news-hpo-keras\",\n",
    "    max_jobs=6,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type=objective_type,\n",
    ")\n",
    "\n",
    "tuner.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 진행 상황 확인\n",
    "\n",
    "HPO 작업은 완료하는 데 시간이 오래 걸릴 수 있으며, 여러 인스턴스에서 각각 여러 훈련 작업을 병렬로 실행할 수 있습니다... 그렇기 때문에 위의 `fit()` 호출은 잠재적으로 혼란스러울 수 있는 통합 로그 스트림을 표시하지 않으며, `wait=False` 매개 변수를 추가하면 완료될 때까지 기다리지 않을 수 있습니다.\n",
    "\n",
    "[**SageMaker 콘솔**](https://console.aws.amazon.com/sagemaker/home#/hyper-tuning-jobs)의 Training > Hyperparameter Tuning Job 페이지로 이동하여 목록에서 작업을 선택합니다.\n",
    "\n",
    "HPO 실행을 위해 트리거된 모든 트레이닝 작업과 전체 요약 지표를 확인할 수 있습니다.\n",
    "\n",
    "물론 API/SDK를 통해서도 이 정보에 액세스할 수 있습니다. 예를 들어 아래와 같이 HPO가 완료될 때까지 기다릴 수 있습니다:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import boto3\n",
    "\n",
    "# Wait until HPO is finished\n",
    "hpo_state = None\n",
    "smclient = boto3.Session().client(\"sagemaker\")\n",
    "\n",
    "while hpo_state is None or hpo_state == \"InProgress\":\n",
    "    if hpo_state is not None:\n",
    "        print(\"-\", end=\"\")\n",
    "        time.sleep(60)  # Poll once every 1 min\n",
    "    hpo_state = smclient.describe_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    "    )[\"HyperParameterTuningJobStatus\"]\n",
    "\n",
    "print(\"\\nHPO state:\", hpo_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 사용하기\n",
    "\n",
    "`estimator`와 마찬가지로 `tuner.deploy()`를 호출하여 HPO 실행에서 찾은 가장 성능이 좋은 모델에서 엔드포인트와 `predictor`를 생성할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검토\n",
    "\n",
    "이 노트북에서는 로컬 코드를 리팩토링하여 SageMaker를 사용하여 동일한 Keras 모델을 학습하고 배포했습니다.\n",
    "\n",
    "이 접근 방식의 몇 가지 이점은 다음과 같습니다:\n",
    "\n",
    "- 학습 작업 기간 동안만 **전문 컴퓨팅 리소스(예: 고성능 또는 GPU 가속 인스턴스)를 자동으로 프로비저닝할 수 있습니다: 활용도가 낮은 리소스를 방치하지 않고 학습에서 우수한 성능을 얻을 수 있습니다.\n",
    "- 사용자가 무엇이 효과가 있고 무엇이 효과가 없었는지를 기록해야 하는 로컬 노트북 실험과 달리, 학습 작업의 이력(매개변수, 메트릭, 출력 등)이 자동으로 추적됩니다.\n",
    "- 학습된 모델은 단 한 번의 SDK 호출로 프로덕션에 바로 사용할 수 있는 안전한 웹 엔드포인트에 배포할 수 있습니다: 동작을 사용자 정의하려는 경우가 아니라면 컨테이너나 웹 애플리케이션 패키징이 필요하지 않습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
