{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TensorFlow Keras MNIST 분류 - 로컬 예제\n",
    "\n",
    "_**(하위 집합인) [MNIST DIGITS](https://en.wikipedia.org/wiki/MNIST_database) 데이터 세트에 대한 TF.Keras CNN 분류기를 학습하고 내보냅니다: 노트북에서 모든 저장 및 계산을 로컬로 수행합니다**_.\n",
    "\n",
    "이 노트북은 SageMaker 스튜디오의 `Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)` 커널 또는 클래식 SageMaker 노트북 인스턴스의 `conda_tensorflow2_p37`에서 잘 작동합니다.\n",
    "\n",
    "---\n",
    "\n",
    "[데이터셋](https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz)은 [AWS의 오픈 데이터 레지스트리](https://registry.opendata.aws/fast-ai-imageclas/)에서 호스팅되며, 각 숫자가 나타내는 폴더에 정리된 PNG 이미지가 포함되어 있습니다.\n",
    "\n",
    ">❓이 노트북의 워크플로우를 SageMaker를 사용하여 더 효과적으로 다시 만드는 방법을 알아낼 수 있습니까?\n",
    "\n",
    "## 내용\n",
    "\n",
    "1. **[노트북 설정](#Notebook-Setup)**\n",
    "1. **[데이터 준비](#Prepare-the-Data)**\n",
    "1. **[파일에서 데이터 로드](#Load-the-Data-From-File)**\n",
    "1. **[CNN을 위한 데이터 사전 처리](#Pre-Process-the-Data-for-our-CNN)**\n",
    "1. **[모델 구축](#Build-a-Model)**\n",
    "1. **[모델 학습](#Fit-the-Model)**\n",
    "1. **[학습 모델 저장](#Save-the-Trained-Model)**\n",
    "1. **[결과 탐색](#Explore-Results)**\n",
    "\n",
    "자세한 지침은 함께 제공되는 **Instructions** 노트를 참조하세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 노트북 설정\n",
    "\n",
    "평소처럼 필요한 라이브러리를 추가로 설치하고 종속 요소를 가져오는 것으로 시작하겠습니다.\n",
    "\n",
    "> ℹ️ **설치 문제 해결**을 참조하세요. 아래의 `ModuleNotFoundError`가 발생하거나 대화형 위젯이 렌더링되지 않는 경우:\n",
    ">\n",
    "> -  아래 `!pip install` 명령을 실행하고 노트북 커널을 재시작한 후 다른 코드 셀을 실행했는지 확인합니다.\n",
    "> -  모듈이 성공적으로 설치된 것처럼 보이지만 노트북 커널 환경에서 누락된 경우, 모듈을 올바른 위치에 설치하려면 `%pip install`을 대신 실행해야 할 수 있습니다.\n",
    "> - 특히 영향을 받는 모듈을 이미 `import`했거나 스튜디오가 아닌 SageMaker 노트북 인스턴스에서 실행 중인 경우, pip 라이브러리를 설치한 후 노트북 커널을 다시 시작해야 할 수 있습니다.\n",
    "> - **`@jupyter-widgets/jupyterlab-manager`** 및 **`ipycanvas`** JupyterLab 위젯이 설치되어 있는지 확인합니다(퍼즐 조각 아이콘 \"Extension Manager\" 사이드바 탭을 사용하거나 보이지 않는 경우 *Settings > Enable Extension Manager*를 클릭합니다). 메시지가 표시되면 JupyterLab을 '재빌드'한 다음 작업을 저장하고 빌드가 완료되면 페이지를 새로고침합니다. Studio에서 시스템 터미널을 열고 `restart-jupyter-server`를 실행해야 할 수도 있습니다.\n",
    ">\n",
    "> 실제로 (그리고 이 워크샵의 CloudFormation 템플릿에서) JupyterLab 확장 프로그램은 일반적으로 사용자가 수동으로 설치하는 대신 [Studio](https://aws.amazon.com/blogs/machine-learning/customize-amazon-sagemaker-studio-using-lifecycle-configurations/) 또는 [노트북 인스턴스](https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html)에 대한 **라이프사이클 구성 스크립트**를 통해 설치됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First install some libraries which might not be available across all kernels:\n",
    "!pip install \"ipycanvas<0.13\" \"ipywidgets<8\" matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ⚠️ ***노트북 커널을 재시작***한 후 계속하세요! (도구 모음의 원형 화살표 버튼)\n",
    "\n",
    "설치 후 커널을 재시작하지 않으면 나중에 대화형 그리기 위젯이 작동하지 않을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# External Dependencies:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Local Notebook Utils:\n",
    "import util\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Using TensorFlow version {tf.__version__}\")\n",
    "print(f\"Keras version {tf.keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "이제 이미지 데이터를 다운로드해 보겠습니다.\n",
    "\n",
    "원본 MNIST 데이터에는 7만 개의 작은 28x28픽셀 PNG 파일(학습 데이터 세트에 6만 개, 테스트 데이터 세트에 1만 개)이 있습니다. 이 형식은 익숙하고 좋은 형식이지만, 많은 수의 작은 파일은 저장과 전송에 비효율적이므로, **성능을 유지하기 위해** 다음과 같이 처리할 것입니다:\n",
    "\n",
    "- 데이터를 `/tmp` 아래의 로컬 임시 폴더에 다운로드합니다(즉, SageMaker의 왼쪽 사이드바에 파일이 표시되지 않음).\n",
    "- 작업할 데이터의 하위 집합만 샘플링합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_dir = \"/tmp/mnist\"\n",
    "training_dir = f\"{local_dir}/training\"\n",
    "testing_dir = f\"{local_dir}/testing\"\n",
    "\n",
    "# Download the MNIST data from the Registry of Open Data on AWS\n",
    "!rm -rf {local_dir}\n",
    "!mkdir -p {local_dir}\n",
    "!aws s3 cp s3://fast-ai-imageclas/mnist_png.tgz {local_dir} --no-sign-request\n",
    "\n",
    "# Un-tar the MNIST data, stripping the leading path element; this will leave us with directories\n",
    "# {local_dir}/testing/ and {local_dir/training/\n",
    "!tar zxf {local_dir}/mnist_png.tgz -C {local_dir}/ --strip-components=1 --no-same-owner\n",
    "\n",
    "# Get the list of files in the training and testing directories recursively\n",
    "train_files = sorted(list(glob.iglob(os.path.join(training_dir, \"*/*.png\"), recursive=True)))\n",
    "test_files = sorted(list(glob.iglob(os.path.join(testing_dir, \"*/*.png\"), recursive=True)))\n",
    "\n",
    "print(f\"Training files: {len(train_files)}\")\n",
    "print(f\"Testing files:  {len(test_files)}\")\n",
    "\n",
    "# Reduce the data by keeping every Nth file and dropping the rest of the files.\n",
    "reduction_factor = 2\n",
    "train_files_to_keep = train_files[::reduction_factor]\n",
    "test_files_to_keep = test_files[::reduction_factor]\n",
    "\n",
    "print(f\"Training files kept: {len(train_files_to_keep)}\")\n",
    "print(f\"Testing files kept:  {len(test_files_to_keep)}\")\n",
    "\n",
    "# Delete all the files not to be kept\n",
    "for fname in set(train_files) ^ set(train_files_to_keep):\n",
    "    os.remove(fname)\n",
    "\n",
    "for fname in set(test_files) ^ set(test_files_to_keep):\n",
    "    os.remove(fname)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일에서 데이터 로드\n",
    "\n",
    "이제 이미지가 `{local_dir}` 폴더에 저장되었으므로 이 파일에서 학습 및 테스트 세트를 읽어와 보겠습니다.\n",
    "```\n",
    "    {local_dir}\n",
    "    |----------------.\n",
    "    `-- testing      `-- training\n",
    "        |-- 0       |-- 0\n",
    "        |               `-- 1.png\n",
    "        |-- 1       |-- 1\n",
    "        |-- 2       |-- 2\n",
    "        |-- 3       |-- 3\n",
    "        |-- 4       |-- 4\n",
    "        |-- 5       |-- 5\n",
    "        |-- 6       |-- 6\n",
    "        |-- 7       |-- 7\n",
    "        |-- 8       |-- 8\n",
    "        `-- 9       `-- 9\n",
    "```\n",
    "\n",
    "(학습 및 테스트 모두) 폴더 이름에서 대상 레이블(`0`-`9`)을 가져와 각 폴더를 반복하고 각 PNG를 이미지 매트릭스에 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "labels = sorted(os.listdir(training_dir))\n",
    "n_labels = len(labels)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "print(\"Loading label \", end=\"\")\n",
    "for ix_label in range(n_labels):\n",
    "    label_str = labels[ix_label]\n",
    "    print(f\"{label_str}...\", end=\"\")\n",
    "    trainfiles = filter(\n",
    "        lambda s: s.endswith(\".png\"),\n",
    "        os.listdir(os.path.join(training_dir, label_str)),\n",
    "    )\n",
    "\n",
    "    for filename in trainfiles:\n",
    "        # Can't just use tf.keras.preprocessing.image.load_img(), because it doesn't close its file\n",
    "        # handles! So get \"Too many open files\" error... Grr\n",
    "        with open(os.path.join(training_dir, label_str, filename), \"rb\") as imgfile:\n",
    "            x_train.append(\n",
    "                # Squeeze (drop) that extra channel dimension, to be consistent with prev format:\n",
    "                np.squeeze(tf.keras.preprocessing.image.img_to_array(Image.open(imgfile)))\n",
    "            )\n",
    "            y_train.append(ix_label)\n",
    "\n",
    "    # Repeat for test data:\n",
    "    testfiles = filter(\n",
    "        lambda s: s.endswith(\".png\"),\n",
    "        os.listdir(os.path.join(testing_dir, label_str)),\n",
    "    )\n",
    "\n",
    "    for filename in testfiles:\n",
    "        with open(os.path.join(testing_dir, label_str, filename), \"rb\") as imgfile:\n",
    "            x_test.append(\n",
    "                np.squeeze(tf.keras.preprocessing.image.img_to_array(Image.open(imgfile)))\n",
    "            )\n",
    "            y_test.append(ix_label)\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Shuffling trainset...\")\n",
    "train_shuffled = [(x_train[ix], y_train[ix]) for ix in range(len(y_train))]\n",
    "np.random.shuffle(train_shuffled)\n",
    "\n",
    "x_train = np.array([datum[0] for datum in train_shuffled])\n",
    "y_train = np.array([datum[1] for datum in train_shuffled])\n",
    "train_shuffled = None\n",
    "\n",
    "print(\"Shuffling testset...\")\n",
    "test_shuffled = [(x_test[ix], y_test[ix]) for ix in range(len(y_test))]\n",
    "np.random.shuffle(test_shuffled)\n",
    "\n",
    "x_test = np.array([datum[0] for datum in test_shuffled])\n",
    "y_test = np.array([datum[1] for datum in test_shuffled])\n",
    "test_shuffled = None\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**계속 진행하기 전에**, 데이터 분포를 빠르게 시각화해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"x_train.shape {x_train.shape}; dtype {x_train.dtype}\")\n",
    "print(f\"y_train.shape {y_train.shape}; dtype {y_train.dtype}\")\n",
    "print(f\"x_test.shape {x_test.shape}; dtype {x_test.dtype}\")\n",
    "print(f\"y_test.shape {y_test.shape}; dtype {y_test.dtype}\")\n",
    "\n",
    "fig = plt.figure(figsize=(14, 3))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.hist(x_train.flatten())\n",
    "ax.set_title(\"Histogram of Training Image Data\")\n",
    "ax.set_ylabel(\"Frequency in Training Set\")\n",
    "ax.set_xlabel(\"Pixel Value\")\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.hist(y_train)\n",
    "ax.set_title(\"Histogram of Training Set Labels\")\n",
    "ax.set_ylabel(\"Frequency in Training Set\")\n",
    "ax.set_xlabel(\"Y Label Value\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터는 레이블 0~9 사이에 꽤 고르게 분포되어 있으며, 이미지는 0에서 255까지의 고정 크기 28x28 행렬로 인코딩되어 있는 것처럼 보입니다. 여기서는 몇 가지 예시를 통해 이해를 돕도록 하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Some example images:\")\n",
    "fig = plt.figure(figsize=(14, 2))\n",
    "for i in range(5):\n",
    "    fig = plt.subplot(1, 5, i + 1)\n",
    "    ax = plt.imshow(x_train[i], cmap=\"gray\")\n",
    "    fig.set_title(f\"Number {y_train[i]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN을 위한 데이터 사전 처리하기\n",
    "\n",
    "다음으로 신경망에 맞게 이 형식을 조정하겠습니다:\n",
    "\n",
    "- 픽셀 값을 정규화하여 숫자 컨디셔닝을 개선합니다.\n",
    "- 각 숫자에 대한 확률의 소프트맥스 분류기 출력에 맞게 레이블을 원핫 인코딩합니다.\n",
    "- 배치 차원(여러 샘플을 병렬로 처리하기 위한)과 채널 차원(예: 흑백 단일 채널을 제외한 3채널 RGB 이미지와 같은)을 모두 추가하고 X축과 Y축을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since we're actually feeding the images in to nets this time, we should actually pay attention\n",
    "# to which way around Keras wants the channel dimension:\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    x_train = np.expand_dims(x_train, 1)\n",
    "    x_test = np.expand_dims(x_train, 1)\n",
    "else:\n",
    "    x_train = np.expand_dims(x_train, len(x_train.shape))\n",
    "    x_test = np.expand_dims(x_test, len(x_test.shape))\n",
    "\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"input_shape:\", input_shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, n_labels)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, n_labels)\n",
    "\n",
    "print(\"n_labels:\", n_labels)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구축\n",
    "\n",
    "이 모델의 핵심은 가능한 모든 레이블에 대한 신뢰도 점수를 산출하는 소프트맥스 출력 레이어가 있는 2D 컨볼루션 네트워크입니다(예: 숫자 = 0~9에 대한 10가지 옵션)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_labels, activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adadelta(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 피팅(학습)\n",
    "\n",
    "Keras를 사용하면 모델 피팅(학습)과 평가가 매우 간단합니다: 적절한 후크가 없어서 기본 로깅에 만족합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size = 128\n",
    "epochs = 12\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=1,  # Hint: You might prefer =2 for running in SageMaker!\n",
    "    validation_data=(x_test, y_test),\n",
    ")\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test loss={score[0]}\")\n",
    "print(f\"Test accuracy={score[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 모델 저장\n",
    "\n",
    "Keras에는 `model.save()` 명령이 내장되어 있으며, TensorFlow v2에서는 이 명령으로 TensorFlow Serving과 호환되는 출력을 직접 생성할 수 있습니다!\n",
    "\n",
    "...하지만 이 노트북은 TensorFlow v1을 실행합니다. 이 명령어를 알아내야 하는 번거로움을 덜어드리기 위해(이 주제에 대한 좋은 블로그 포스팅이 있습니다. [여기](https://aws.amazon.com/blogs/machine-learning/deploy-trained-keras-or-tensorflow-models-using-amazon-sagemaker/)), 여기서는 모델을 TensorFlow Serving-ready 형식으로 저장하여 힌트를 드리겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The export folder needs to be empty, or non-existent\n",
    "!rm -rf data/model/model/1\n",
    "\n",
    "# Please ignore Layer.updates(...) warning if any while running the notebook in < TFv2.4\n",
    "model.save(os.path.join(\"data/model\", \"model/1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 탐색\n",
    "\n",
    "모델을 시험해 보기 위해 테스트 세트에서 샘플 이미지를 가져와서 레이블을 예측하고 플로팅할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose an image:\n",
    "label = \"3\"\n",
    "filename = os.listdir(f\"{testing_dir}/{label}\")[0]\n",
    "\n",
    "# Load the image (and normalize to 0-1):\n",
    "img = tf.keras.preprocessing.image.img_to_array(\n",
    "    Image.open(f\"{testing_dir}/{label}/{filename}\")\n",
    ") / 255\n",
    "\n",
    "# Expand out the \"batch\" dimension, and send to the model:\n",
    "result = model.predict(np.expand_dims(img, 0))\n",
    "print(f\"Result confidences: {result}\")\n",
    "\n",
    "# Plot the result:\n",
    "plt.figure(figsize=(3, 3))\n",
    "fig = plt.subplot(1, 1, 1)\n",
    "ax = plt.imshow(np.squeeze(img), cmap=\"gray\")\n",
    "fig.set_title(f\"Predicted Number {np.argmax(result[0])}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모두 완료되었습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
